{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qr requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials, SpotifyOAuth\n",
    "import json\n",
    "import webbrowser\n",
    "import datetime\n",
    "\n",
    "\n",
    "client_id = '5f6ad0b8fc02496783286ff99db144b8' #CHANGE FOR SPOTIFY DEVICE\n",
    "client_secret = '13a94c2e1b594781ac7830bca5410b51' #CHANGE FOR SPOTIFY DEVICE\n",
    "\n",
    "def add_to_queue(inp):\n",
    "\n",
    "    scope = \"user-modify-playback-state\"\n",
    "    sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        redirect_uri='https://www.google.com/',\n",
    "        scope=scope))\n",
    "    print(\"Added to queue\")\n",
    "    \n",
    "    search_str = inp\n",
    "    artist_name=[]\n",
    "    track_name = []\n",
    "    track_id = []\n",
    "    result = sp.search(search_str, type='track')\n",
    "    for i, t in enumerate(result['tracks']['items']):\n",
    "        artist_name.append(t['artists'][0]['name'])\n",
    "        track_name.append(t['name'])\n",
    "        track_id.append(t['id'])\n",
    "    \n",
    "    print(artist_name[0])\n",
    "    print(track_name[0])\n",
    "\n",
    "\n",
    "    #print(result)\n",
    "    sp.add_to_queue(track_id[0])\n",
    "\n",
    "def skip_song():\n",
    "\n",
    "    scope = \"user-modify-playback-state\"\n",
    "    sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        redirect_uri='https://www.google.com/',\n",
    "        scope=scope))\n",
    "    print(\"skipping\")\n",
    "\n",
    "    # Skip to the next track\n",
    "    sp.next_track()\n",
    "\n",
    "#PARAMS TO CHANGE\n",
    "accuracy_window = 60 #currently has to be smaller than 10 cuz thats the initial list size/2\n",
    "decrease_to_skip = 0.6 #percentage decrease needed to skip song\n",
    "seconds_to_skip = 30 #number of seconds after the last song was skipped so that the next song can skip\n",
    "\n",
    "hand_values = [0 for i in range(120)] #fills the list with 0s\n",
    "head_values = [0 for i in range(120)]\n",
    "\n",
    "last_time_skipped = [datetime.datetime.now()]\n",
    "\n",
    "def add_new_values(head=None, hand=None): #run every time a new head or hand count is found\n",
    "\n",
    "    skip_bool = False\n",
    "    #start_skip = False\n",
    "\n",
    "    #SKIP FOR HANDS\n",
    "    if hand is not None:\n",
    "        hand_values.insert(0, hand)\n",
    "\n",
    "        current_max = max(hand_values[0:accuracy_window])#sum(hand_values[0:accuracy_window])/accuracy_window\n",
    "        previous_max = max(hand_values[accuracy_window:accuracy_window*2])#sum(hand_values[accuracy_window:accuracy_window*2])/accuracy_window\n",
    "    \n",
    "        if current_max < decrease_to_skip * previous_max:\n",
    "            current_time = datetime.datetime.now()\n",
    "            print(\"time passed:\", (current_time - last_time_skipped[0]).total_seconds())\n",
    "            if (current_time - last_time_skipped[0]).total_seconds() > seconds_to_skip:\n",
    "                print(\"Skipping Song!\")\n",
    "                #skip_song()\n",
    "                last_time_skipped[0] = datetime.datetime.now()\n",
    "                skip_bool = True\n",
    "                #start_skip = False\n",
    "            else: \n",
    "                print(\"Not enough time to skip song!!\")\n",
    "                #start_skip = True\n",
    "\n",
    "    if hand is not None: \n",
    "        hand_values.insert(0, hand)\n",
    "\n",
    "    #SKIP FOR HEADS\n",
    "    if head is not None:\n",
    "        hand_values.insert(0, head)\n",
    "\n",
    "        current_max = max(hand_values[0:accuracy_window])\n",
    "        previous_max = max(hand_values[accuracy_window:accuracy_window*2])\n",
    "\n",
    "        if current_max < decrease_to_skip * previous_max:\n",
    "            current_time = datetime.datetime.now()\n",
    "            print(\"time passed:\", (current_time - last_time_skipped[0]).total_seconds())\n",
    "            if (current_time - last_time_skipped[0]).total_seconds() > seconds_to_skip:\n",
    "                print(\"Skipping Song!\")\n",
    "                #skip_song() MAKE SURE YOU UNCOMMENT TOMORROW\n",
    "                last_time_skipped[0] = datetime.datetime.now()\n",
    "                skip_bool = True\n",
    "                #start_skip = False\n",
    "            else: \n",
    "                print(\"Not enough time to skip song!!\")\n",
    "                #start_skip = True\n",
    "\n",
    "    if head is not None: \n",
    "        head_values.insert(0, head)\n",
    "\n",
    "    print(\"hand vals:\", hand_values)\n",
    "    print(\"head vals:\", head_values)\n",
    "\n",
    "    return skip_bool#, start_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "1/1: 0...  Success (inf frames 1280x720 at 30.00 FPS)\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/var/folders/t4/5jwm4m814g5g3vhdxm2lslch0000gn/T/ipykernel_45766/1680756056.py\", line 57, in inference\n",
      "    start_time = datetime.datetime.now()\n",
      "NameError: name 'datetime' is not defined\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/tkinter/__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/var/folders/t4/5jwm4m814g5g3vhdxm2lslch0000gn/T/ipykernel_45766/1680756056.py\", line 57, in inference\n",
      "    start_time = datetime.datetime.now()\n",
      "NameError: name 'datetime' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Webcam feed\n",
    "  \n",
    "from tkinter import *\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams\n",
    "from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, smart_inference_mode\n",
    "\n",
    "# Directories\n",
    "save_dir = increment_path(Path('runs/detect') / 'exp', exist_ok=False)  # increment run\n",
    "(save_dir / 'labels' if False else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "#source = check_file(\"party_trimmed_recommendation.mp4\")\n",
    "model = DetectMultiBackend(\"partyai_model.pt\")#, device='', dnn=False, data=None, fp16=False)\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz=(640, 640)\n",
    "dataset = LoadStreams(\"0\", img_size=imgsz, stride=stride, auto=pt, vid_stride=1) #load from webcam\n",
    "bs = len(dataset)\n",
    "dataset = iter(dataset) #[(path, im, im0s, vid_cap, s) for path, im, im0s, vid_cap, s in dataset]\n",
    "\n",
    "vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "\n",
    "# Create a GUI app\n",
    "app = Tk()\n",
    "  \n",
    "# Bind the app with Escape keyboard to\n",
    "# quit app whenever pressed\n",
    "app.bind('<Escape>', lambda e: app.quit())\n",
    "\n",
    "# Label Creation\n",
    "tracking_lbl = Label(app, text = \"\")\n",
    "tracking_lbl.pack()\n",
    "\n",
    "# Create a label and display it on app\n",
    "label_widget = Label(app)\n",
    "label_widget.pack()\n",
    "label_widget.configure(height = 40, width=71)\n",
    "\n",
    "# Run inference\n",
    "model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup\n",
    "\n",
    "def inference(prev_headcount = 0, prev_handcount = 0):\n",
    "    start_time = datetime.datetime.now()\n",
    "    button1.pack_forget() #make button invisible\n",
    "    try:\n",
    "        path, im, im0s, vid_cap, s = next(dataset)  # get the next image from the iterator\n",
    "    except StopIteration:\n",
    "        return  # if there are no more images, do nothing\n",
    "    \n",
    "    windows, dt = [], (Profile(), Profile(), Profile())\n",
    "\n",
    "    with dt[0]:\n",
    "        im = torch.from_numpy(im).to(model.device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "\n",
    "    # Inference\n",
    "    with dt[1]:\n",
    "        visualize = False #increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=False, visualize=visualize)\n",
    "\n",
    "    # NMS\n",
    "    with dt[2]:\n",
    "        pred = non_max_suppression(pred, conf_thres=0.7, iou_thres=0.75, classes=None, agnostic=False, max_det=1000)\n",
    "\n",
    "    head_count = 0\n",
    "    hand_count = 0\n",
    "\n",
    "    # Process predictions\n",
    "    for i, det in enumerate(pred):  # per image\n",
    "        p, im0 = path[i], im0s[i].copy()\n",
    "        s += f'{i}: '\n",
    "        annotator = Annotator(im0, line_width=3, example=str(names))\n",
    "        s = 'PartyAI sees '\n",
    "        if len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "            count = {\"heads\": 0, \"hands\": 0}\n",
    "            # Print results\n",
    "            for c in det[:, 5].unique():\n",
    "                n = (det[:, 5] == c).sum()  # detections per class\n",
    "                s += f\"{n} {names[int(c)]}, \"  # add to string\n",
    "                count[names[int(c)]] = int(n)\n",
    "            head_count = count['heads']\n",
    "            hand_count = count['hands']\n",
    "            s = s[:-2]\n",
    "            skipped = add_new_values(head=head_count, hand=hand_count)\n",
    "            if skipped: \n",
    "                lbl.config(text = \"Song Skipped!\")\n",
    "            elif count['heads'] > prev_headcount:\n",
    "                lbl.config(text = \"\")\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                if True:  # Add bbox to image\n",
    "                    c = int(cls)  # integer class\n",
    "                    label = None if False else (names[c] if False else f'{names[c]} {conf:.2f}')\n",
    "                    annotator.box_label(xyxy, label, color=colors(c+8, True))\n",
    "\n",
    "        # Stream results\n",
    "        im0 = annotator.result()\n",
    "        print(\"FPS: \", round(1/(datetime.datetime.now() - start_time).total_seconds()))\n",
    "\n",
    "        img = Image.fromarray(im0).resize((640, 640))\n",
    "        imgtk = ImageTk.PhotoImage(image = img)\n",
    "        label_widget.imgtk = imgtk\n",
    "        label_widget.configure(image=imgtk, height = 640, width=640)\n",
    "        label_widget.after(10, inference, head_count, hand_count)\n",
    "        tracking_lbl.config(text = s)\n",
    "\n",
    "# # Create a button to open the camera in GUI app\n",
    "button1 = Button(app, text=\"Start Live Stream\", command=inference, width=15)\n",
    "button1.pack()\n",
    "\n",
    "def addSong2Queue():\n",
    "    inp = inputtxt.get(1.0, \"end-1c\")\n",
    "    add_to_queue(inp)\n",
    "    lbl.config(text = \"Song Queued: \"+inp)\n",
    "\n",
    "# # Create a button to open the camera in GUI app\n",
    "button2 = Button(app, text=\"Add Song to Queue\", command=addSong2Queue, width=15)\n",
    "button2.pack()\n",
    "\n",
    "# TextBox Creation\n",
    "inputtxt = Text(app,\n",
    "                   height = 2,\n",
    "                   width = 15)\n",
    "  \n",
    "inputtxt.pack()\n",
    "\n",
    "# Label Creation\n",
    "lbl = Label(app, text = \"\")\n",
    "lbl.pack()\n",
    "\n",
    "# Create an infinite loop for displaying app on screen\n",
    "app.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6372508df1359f9ee3e1a33d03fcb25c65c9a263c4654aa5c4433f9b9b8551"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
